{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "\n",
    "We provide this notebook for inference and visualizations. \n",
    "\n",
    "You can either load images from a dataloader(see Sec. 1) or from a local path(see Sec. 2).\n",
    "\n",
    "Welcome to join [IDEA](https://idea.edu.cn/en)([中文网址](https://idea.edu.cn/))!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import torch, json\n",
    "import numpy as np\n",
    "\n",
    "from main import build_model_main\n",
    "from util.slconfig import SLConfig\n",
    "from datasets import build_dataset\n",
    "from util.visualizer import COCOVisualizer\n",
    "from util import box_ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Initialize and Load Pre-trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_path = \"config/DINO/DINO_4scale_swin.py\" # change the path of the model config file\n",
    "model_checkpoint_path = \"checkpoint_best.pth\" # change the path of the model checkpoint\n",
    "# See our Model Zoo section in README.md for more details about our pretrained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chulanpro/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MultiScaleDeformableAttention'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# args.device = 'cuda:4' \u001b[39;00m\n\u001b[1;32m      3\u001b[0m args\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m \n\u001b[0;32m----> 4\u001b[0m model, criterion, postprocessors \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_model_main\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(model_checkpoint_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/Desktop/ai-city/DINO/main.py:80\u001b[0m, in \u001b[0;36mbuild_model_main\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model_main\u001b[39m(args):\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# we use register to maintain models from catdet6 on.\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MODULE_BUILD_FUNCS\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m args\u001b[38;5;241m.\u001b[39mmodelname \u001b[38;5;129;01min\u001b[39;00m MODULE_BUILD_FUNCS\u001b[38;5;241m.\u001b[39m_module_dict\n\u001b[1;32m     82\u001b[0m     build_func \u001b[38;5;241m=\u001b[39m MODULE_BUILD_FUNCS\u001b[38;5;241m.\u001b[39mget(args\u001b[38;5;241m.\u001b[39mmodelname)\n",
      "File \u001b[0;32m~/Desktop/ai-city/DINO/models/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# DINO\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2022 IDEA. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 [see LICENSE for details]\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dino\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_model\u001b[39m(args):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m build(args)\n",
      "File \u001b[0;32m~/Desktop/ai-city/DINO/models/dino/__init__.py:10\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Conditional DETR\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2021 Microsoft. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dino\n",
      "File \u001b[0;32m~/Desktop/ai-city/DINO/models/dino/dino.py:33\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmatcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_matcher\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msegmentation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (DETRsegm, PostProcessPanoptic, PostProcessSegm,\n\u001b[1;32m     32\u001b[0m                            dice_loss)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeformable_transformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_deformable_transformer\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sigmoid_focal_loss, MLP\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregistry\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MODULE_BUILD_FUNCS\n",
      "File \u001b[0;32m~/Desktop/ai-city/DINO/models/dino/deformable_transformer.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmisc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m inverse_sigmoid\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_encoder_output_proposals, MLP,_get_activation_fn, gen_sineembed_for_position\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MSDeformAttn\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mDeformableTransformer\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, d_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, nhead\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, \n\u001b[1;32m     28\u001b[0m                  num_queries\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, \n\u001b[1;32m     29\u001b[0m                  num_encoder_layers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m                  use_detached_boxes_dec_out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     73\u001b[0m                  ):\n",
      "File \u001b[0;32m~/Desktop/ai-city/DINO/models/dino/ops/modules/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Deformable DETR\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2020 SenseTime. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Modified from https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch/tree/pytorch_1.0.0\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mms_deform_attn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MSDeformAttn\n",
      "File \u001b[0;32m~/Desktop/ai-city/DINO/models/dino/ops/modules/ms_deform_attn.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xavier_uniform_, constant_\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MSDeformAttnFunction\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_power_of_2\u001b[39m(n):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, \u001b[38;5;28mint\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m (n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "File \u001b[0;32m~/Desktop/ai-city/DINO/models/dino/ops/functions/__init__.py:9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Deformable DETR\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2020 SenseTime. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Modified from https://github.com/chengdazhi/Deformable-Convolution-V2-PyTorch/tree/pytorch_1.0.0\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mms_deform_attn_func\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MSDeformAttnFunction\n",
      "File \u001b[0;32m~/Desktop/ai-city/DINO/models/dino/ops/functions/ms_deform_attn_func.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Function\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunction\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m once_differentiable\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mMultiScaleDeformableAttention\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mMSDA\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMSDeformAttnFunction\u001b[39;00m(Function):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(ctx, value, value_spatial_shapes, value_level_start_index, sampling_locations, attention_weights, im2col_step):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MultiScaleDeformableAttention'"
     ]
    }
   ],
   "source": [
    "args = SLConfig.fromfile(model_config_path) \n",
    "# args.device = 'cuda:4' \n",
    "args.device = 'cpu' \n",
    "model, criterion, postprocessors = build_model_main(args)\n",
    "checkpoint = torch.load(model_checkpoint_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_box_strided_yolo_fusion(img, boxes, scores, labels, confidence_threshold = 0.3):\n",
    "    image = img.copy()\n",
    "    image_height, image_width, _ = image.shape\n",
    "    \n",
    "    # loop over each of the detection\n",
    "    for box, score, label in zip(boxes, scores, labels):\n",
    "        # extract the confidence of the detection\n",
    "        # draw bounding boxes only if the detection confidence is above...\n",
    "        # ... a certain threshold, else skip\n",
    "        if score > confidence_threshold:\n",
    "            # get the class id\n",
    "            class_name = str(label)\n",
    "\n",
    "            color = (0, 255, 255)\n",
    "            # get the bounding box coordinates\n",
    "            box_x, box_y, box_width, box_height =  [box[0], box[1], box[2], box[3]]\n",
    "            # draw a rectangle around each detected object\n",
    "            cv2.rectangle(image, (int(box_x), int(box_y)), (int(box_width), int(box_height)), color, thickness=4)\n",
    "            # put the text on top of the frame\n",
    "            cv2.putText(image, str(round(score,2)), (int(box_x), int(box_y - 5)), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "    \n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "    return image\n",
    "\n",
    "def get_image_id(img_name):\n",
    "  img_name = img_name.split('.png')[0] if img_name.endswith('.png') else img_name.split('.txt')[0]\n",
    "  sceneList = ['M', 'A', 'E', 'N']\n",
    "  cameraIndx = int(img_name.split('_')[0].split('camera')[1])\n",
    "  sceneIndx = sceneList.index(img_name.split('_')[1])\n",
    "  frameIndx = int(img_name.split('_')[2])\n",
    "  imageId = int(str(cameraIndx)+str(sceneIndx)+str(frameIndx))\n",
    "  return imageId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2712/2712 [16:12<00:00,  2.79it/s]\n"
     ]
    }
   ],
   "source": [
    "folder_image = \"/home/nghiemtd/ICML_2024/Track_4/datasets/fullFisheye/test/images\"\n",
    "transform = T.Compose([\n",
    "    T.RandomResize([800], max_size=1333),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "dt_json = []\n",
    "for index, name in enumerate(tqdm(os.listdir(folder_image))):\n",
    "    if index > 3:\n",
    "        break\n",
    "    file_image = os.path.join(folder_image, name)\n",
    "    \n",
    "    image = Image.open(file_image).convert(\"RGB\")\n",
    "    image_or = np.asarray(image)\n",
    "    image_height, image_width, _ = np.asarray(image).shape\n",
    "    image, _ = transform(image, None)\n",
    "    output = model.cuda()(image[None].cuda())\n",
    "    output = postprocessors['bbox'](output, torch.Tensor([[1.0, 1.0]]).cuda())[0]\n",
    "    boxes = output['boxes'].cpu().tolist()\n",
    "    new_boxes = []\n",
    "    for out in boxes:\n",
    "        new_boxes.append([out[0]*image_width, out[1]*image_height, out[2]*image_width, out[3]*image_height])\n",
    "#     print(new_boxes)\n",
    "    scores = output['scores'].cpu().tolist()\n",
    "    labels = output['labels'].cpu().tolist()\n",
    "#     a = display_box_strided_yolo_fusion(image_or, new_boxes, scores, labels, confidence_threshold = 0.3)\n",
    "    for box, score, label in zip(new_boxes, scores, labels):\n",
    "        # extract the confidence of the detection\n",
    "        # draw bounding boxes only if the detection confidence is above...\n",
    "        # ... a certain threshold, else skip\n",
    "        if score >= 0.0:\n",
    "            dt_json.append({\n",
    "                'image_id': get_image_id(name),\n",
    "                'category_id': int(label),\n",
    "                'bbox': [box[0], box[1], (box[2]-box[0]), (box[3]-box[1])],\n",
    "                'score': float(score)\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(dt_json, open('test_dt_pre.json', 'w')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preds_to_coco_dt(preds, conf=0.5):\n",
    "    coco_dt = []\n",
    "    for obj in preds:\n",
    "        if obj['score'] >= conf:\n",
    "            coco_dt.extend([\n",
    "                {\n",
    "                  'image_id': int(obj['image_id']),\n",
    "                  'category_id': obj['category_id'],\n",
    "                  'bbox': [obj['bbox'][0], obj['bbox'][1], obj['bbox'][2], obj['bbox'][3]],\n",
    "                  'score': obj['score']\n",
    "                } \n",
    "            ])\n",
    "    return coco_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = json.load(open('test_dt_pre.json'))\n",
    "test_dt_json = preds_to_coco_dt(test_preds, conf=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=11.63s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.74s).\n",
      " Average area under PR curve    (mAP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.311\n",
      " Average area under PR curve    (mAP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.520\n",
      " Average area under PR curve    (mAP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.324\n",
      " Average area under PR curve    (mAP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.187\n",
      " Average area under PR curve    (mAP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.511\n",
      " Average area under PR curve    (mAP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.796\n",
      " Average Recall                 (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.212\n",
      " Average Recall                 (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.340\n",
      " Average Recall                 (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.350\n",
      " Average Recall                 (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.228\n",
      " Average Recall                 (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.559\n",
      " Average Recall                 (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.838\n",
      " Average Precision              AP @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.572\n",
      " Average Precision              AP @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.501\n",
      " Average Precision              AP @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.490\n",
      " Average Precision              AP @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.379\n",
      " Average Precision              AP @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.632\n",
      " Average Precision              AP @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.845\n",
      " Average f1 score               F1 @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.284\n",
      " Average f1 score               F1 @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.402\n",
      " Average f1 score               F1 @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.407\n",
      " Average f1 score               F1 @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.281\n",
      " Average f1 score               F1 @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.592\n",
      " Average f1 score               F1 @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.840\n",
      "----------------------------------------\n",
      "AP_0.5-0.95 0.3112846487200417\n",
      "AP_0.5 0.520488496257767\n",
      "AP_S 0.18714398740196106\n",
      "AP_M 0.5109062638008328\n",
      "AP_L 0.7963332798510594\n",
      "f1_score:  0.40655937481296045\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from FishEye8K.evaluation_Linux.pycocotools.coco import COCO\n",
    "from FishEye8K.evaluation_Linux.pycocotools.cocoeval_modified import COCOeval\n",
    "\n",
    "coco_gt = COCO('/home/nghiemtd/ICML_2024/Track_4/test_gt.json')\n",
    "coco_dt = coco_gt.loadRes(test_dt_json)\n",
    "\n",
    "coco_eval = COCOeval(coco_gt, coco_dt, 'bbox')\n",
    "# coco_eval.params.catIds = [0, 1, 2, 4]\n",
    "coco_eval.evaluate()\n",
    "coco_eval.accumulate()\n",
    "coco_eval.summarize()\n",
    "\n",
    "print('----------------------------------------')\n",
    "print('AP_0.5-0.95', coco_eval.stats[0])\n",
    "print('AP_0.5', coco_eval.stats[1])\n",
    "print('AP_S', coco_eval.stats[3])\n",
    "print('AP_M', coco_eval.stats[4])\n",
    "print('AP_L', coco_eval.stats[5])\n",
    "print('f1_score: ', coco_eval.stats[20])\n",
    "print('----------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0ad18b9cce5171a92b1ace78d675cb7cfe7b38ef1dfda11fe1bc29cba1874dd4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
